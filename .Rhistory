start_row = indices[1]
end_row = indices[2]
# extract rows in a batch
rows = X[start_row:end_row, , drop = FALSE]
# compute leverage for all rows in the batch
leverage = rowSums(rows * (rows %*% XtX_inv))
names(leverage) = str_c("row",start_row:end_row)
# save results in a single file for the batch
batch_filename = file.path(leverage_dir, str_c("leverage_", start_row, "_", end_row, ".rds"))
saveRDS(leverage, file = batch_filename)
}
# function to create batches
create_batches = function(n_rows, batch_size) {
# start indices of batches
starts = seq(1, n_rows, by = batch_size)
# end indices of batches
ends = pmin(starts + batch_size - 1, n_rows)
# combine into a list of start and end indices
batches = Map(c, starts, ends)
return(batches)
}
# create batch indices
batches = create_batches(nrow(X), BATCH_SIZES)
# test
compute_leverage_batches(batches[[1]])
knitr::opts_chunk$set(echo = TRUE)
source("readSpectra.R")
library(Matrix)
library(parallel)
library(pbmcapply)
#library(lme4)
#library(car)
#library(emmeans)
#library(boot)
# autocorrelation
#library(collapse)
#library(glmm)
#library(MASS)
#library(gridExtra)
#library(glmnet)
#library(plm)
#library(sandwich)
#library(lmtest)
# working directory with the data
wd_data = "/Users/josephsalzer/research/exostat/"
# RESPONSE variable
RESPONSE = "rv_template_0.5"
# names of the timeID, lineID, and timeGroupID
TIME_ID_NAME = "date"
LINE_ID_NAME = "line_order"
TIMEGROUP_ID_NAME = "date_groups"
model_name = "Gauss=all_HG=all"
model_fit = readRDS(str_c(wd_data, "models/", model_name, "/model.rds" ))
# get the lm fit and dataframe
designMat = model_fit$designMat
responses = model_fit$responses
rv_df = model_fit$df
group_sizes = model_fit$group_sizes
modelFormula = model_fit$modelFormula
covariates = model_fit$covariates
fit_lm = model_fit$fit_lm
leverages = model_fit$leverages
RMSE = model_fit$RMSE
# vec of LineIDs  in completeLines_df
lineIDs = rv_df %>% group_by(!!sym(LINE_ID_NAME)) %>% summarize(n. = n()) %>% pull(!!sym(LINE_ID_NAME))
# vec of timeIDs in completeLines_df
timeIDs = rv_df %>% group_by(!!sym(TIME_ID_NAME)) %>% summarize(n. = n()) %>% pull(!!sym(TIME_ID_NAME))
T_ = length(timeIDs)
L_ = length(lineIDs)
# dataframe of coefficients of current model
coef_df = tibble( coef = rownames( fit_lm$beta_hat ),
estimate = fit_lm$beta_hat[,1],
se = sqrt( diag(fit_lm$var_beta_hat) ) )
# clean RV df with +- se
cleanRV_df = model_fit$cleanRV_df %>%
mutate(lowerSE_MLE = estimate - se,
upperSE_MLE = estimate +se)
cat(model_name, "\n",
str_c("AIC: ", round(fit_lm$AIC/1e5,3), "e5" ), "\n",
str_c("BIC: ", round(fit_lm$BIC/1e5,3), "e5" ), "\n",
str_c("RSE: ", round(fit_lm$RSE,4), "\n" ),
str_c("Parameters: ", ncol(designMat), "\n"),
str_c("RMSE of cleaned RV to true planet: ", round(model_fit$RMSE,3) ), "\n",
str_c("mean se: ", round(mean( cleanRV_df$se ),3) ), "\n",
str_c("coverage 1se: ",
round(mean((cleanRV_df$estimate - cleanRV_df$se < 0) & (cleanRV_df$estimate + cleanRV_df$se > 0)),3),
"\n"),
str_c("coverage 2se: ",
round(mean((cleanRV_df$estimate - 2*cleanRV_df$se < 0) & (cleanRV_df$estimate + 2*cleanRV_df$se > 0)),3),
"\n"))
cat(model_name, "&",
ncol(designMat), "&",
str_c( "$", round(fit_lm$AIC/1e5,3), " \\times 10^5$"), "&",
str_c( "$", round(fit_lm$BIC/1e5,3), " \\times 10^5$"), "&",
round(fit_lm$RSE,3), "&",
round(model_fit$RMSE,3), "\\\\"
)
ggplot( mapping = aes(x = cleanRV_df$timeID) ) +
geom_point(mapping = aes(y = cleanRV_df$estimate), size = 1.2) +
#geom_errorbar(mapping = aes(ymin = cleanRV_df$lowerSE_MLE, ymax = cleanRV_df$upperSE_MLE), color = "black",linewidth = 1) +
geom_hline(yintercept = 0, color = "red") +
ylab("Cleaned RV") +
xlab("Date") +
theme_bw() +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 20))
ggplot( mapping = aes(x = cleanRV_df$timeID) ) +
geom_point(mapping = aes(y = cleanRV_df$estimate), size = 1.2) +
geom_hline(yintercept = 0, color = "red") +
ylab("Cleaned RV") +
xlab("Date") +
theme_bw() +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 20))
ggplot() +
geom_point(mapping = aes(x = fit_lm$y_hat[,1], y = fit_lm$resid[,1]), size = .15, alpha = .5) +
theme_minimal() +
labs(title = "fitted rv and residual plot",
x = "fitted rv",
y = "residuals") +
ylim(-100,100) +
xlim(-200,200)
# QQ plot
ggplot(data.frame(sample = fit_lm$resid[,1]), aes(sample = sample)) +
stat_qq(size = .5, alpha = .5) +
stat_qq_line() +
labs(title = "QQ Plot",
x = "Theoretical Quantiles",
y = "Sample Quantiles") +
theme_minimal()
ggplot() + geom_density(mapping = aes(x = leverages))
summary(leverages)
readRDS(str_c(wd_data, "models/", model_name, "/leverages" ))
knitr::opts_chunk$set(echo = TRUE)
source("readSpectra.R")
library(Matrix)
library(parallel)
library(pbmcapply)
# get the list of all .rds files in the leverage directory
leverage_files = list.files(path = leverage_dir, pattern = "\\.rds$", full.names = TRUE)
# directory containing the leverage files
leverage_dir = str_c(WD_DATA, "models/", MODEL_NAME, "/leverages")
# arguments passed to command line
# model name
MODEL_NAME = "Gauss=all_HG=all"
BATCH_SIZES = 1000
# working directory with the data
WD_DATA = "/Users/josephsalzer/research/exostat/"
# read in the model fit
model_fit = readRDS(str_c(WD_DATA, "models/", MODEL_NAME, "/model.rds"))
fit_lm = model_fit$fit_lm
X = model_fit$designMat
XtX_inv = (fit_lm$var_beta_hat)/fit_lm$sigma2_hat
# directory containing the leverage files
leverage_dir = str_c(WD_DATA, "models/", MODEL_NAME, "/leverages")
# create directory called "leverages" in model name
if ( !dir.exists(leverage_dir) ) {
dir.create(leverage_dir)
}
# get the list of all .rds files in the leverage directory
leverage_files = list.files(path = leverage_dir, pattern = "\\.rds$", full.names = TRUE)
# initialize an empty vector to store the combined leverage values
leverages = vector()
for (file in leverage_files) {
leverages = c(leverages, readRDS(file))
}
rm(leverage_files)
length(leverages)
str_c(wd_data, "models/", model_name, "/leverages" )
str_c(wd_data, "models/", model_name )
str_c(wd_data, "models/", model_name, "/leverages.rds" )
saveRDS(leverages,
str_c(wd_data, "models/", model_name, "/leverages.rds" ))
# arguments passed to command line
# model name
MODEL_NAME = "Gauss=all_HG=all"
BATCH_SIZES = 1000
# working directory with the data
WD_DATA = "/Users/josephsalzer/research/exostat/"
# read in the model fit
model_fit = readRDS(str_c(WD_DATA, "models/", MODEL_NAME, "/model.rds"))
fit_lm = model_fit$fit_lm
X = model_fit$designMat
XtX_inv = (fit_lm$var_beta_hat)/fit_lm$sigma2_hat
# directory containing the leverage files
leverage_dir = str_c(WD_DATA, "models/", MODEL_NAME, "/leverages")
# create directory called "leverages" in model name
if ( !dir.exists(leverage_dir) ) {
dir.create(leverage_dir)
}
# get the list of all .rds files in the leverage directory
leverage_files = list.files(path = leverage_dir, pattern = "\\.rds$", full.names = TRUE)
# initialize an empty vector to store the combined leverage values
leverages = vector()
for (file in leverage_files) {
leverages = c(leverages, readRDS(file))
}
rm(leverage_files)
head(leverages)
head(leverages)
length(leverages)
saveRDS(leverages,
str_c(WD_DATA, "models/", model_name, "/leverages.rds" ))
saveRDS(leverages,
str_c(WD_DATA, "models/", MODEL_NAME, "/leverages.rds" ))
knitr::opts_chunk$set(echo = TRUE)
source("readSpectra.R")
library(Matrix)
library(parallel)
library(pbmcapply)
# arguments passed to command line
# model name
MODEL_NAME = "Gauss=all_HG=all"
NUM_BOOTS = 500
# working directory with the data
WD_DATA = "/Users/josephsalzer/research/exostat/"
# names of the timeID, lineID, and timeGroupID
TIME_ID_NAME = "date"
LINE_ID_NAME = "line_order"
# directory containing the bootstrap files
bootstrap_dir = str_c(WD_DATA, "models/", MODEL_NAME, "/wild_bootstraps" )
# create directory called "bootstrap" in model name
if ( !dir.exists(bootstrap_dir) ) {
dir.create(bootstrap_dir)
}
# read in the model fit
model_fit = readRDS(str_c(WD_DATA, "models/", MODEL_NAME, "/model.rds"))
# lm fit, df, design matrix and leverages
fit_lm = model_fit$fit_lm
rv_df = model_fit$df
designMat = model_fit$designMat
leverages = model_fit$leverages
# vec of LineIDs  in completeLines_df
lineIDs = rv_df %>% group_by(!!sym(LINE_ID_NAME)) %>% summarize(n. = n()) %>% pull(!!sym(LINE_ID_NAME))
# vec of timeIDs in completeLines_df
timeIDs = as.Date(rv_df %>% group_by(!!sym(TIME_ID_NAME)) %>% summarize(n. = n()) %>% pull(!!sym(TIME_ID_NAME)))
T_ = length(timeIDs)
L_ = length(lineIDs)
# read in the model fit
model_fit = readRDS(str_c(WD_DATA, "models/", MODEL_NAME, "/model.rds"))
# lm fit, df, design matrix and leverages
fit_lm = model_fit$fit_lm
rv_df = model_fit$df
designMat = model_fit$designMat
leverages = readRDS(str_c(WD_DATA, "models/", MODEL_NAME, "/leverages.rds" ))
# vec of LineIDs  in completeLines_df
lineIDs = rv_df %>% group_by(!!sym(LINE_ID_NAME)) %>% summarize(n. = n()) %>% pull(!!sym(LINE_ID_NAME))
# vec of timeIDs in completeLines_df
timeIDs = as.Date(rv_df %>% group_by(!!sym(TIME_ID_NAME)) %>% summarize(n. = n()) %>% pull(!!sym(TIME_ID_NAME)))
T_ = length(timeIDs)
L_ = length(lineIDs)
rv_df
leverages
summary(leverages)
# get modified residuals
u_hat = fit_lm$resid/(1-leverages)
# get unmodified residuals
#u_hat = fit_lm$resid
# assign blocks for the bootstrap (by line)
block_size = length(timeIDs)
rv_df = rv_df %>%
arrange(!!sym(LINE_ID_NAME),!!sym(TIME_ID_NAME)) %>%
mutate(boot_block = factor( ceiling(row_number() / block_size) ) )
rv_df
rv_df %>%
select(!!sym(LINE_ID_NAME),!!sym(TIME_ID_NAME),boot_block)
rv_df
rv_df %>%
group_by(line_order) %>%
mutate(boot_block1 = 1:length(lineIDs))
rv_df %>%
group_by(line_order) %>%
mutate(boot_block1 = 1:row_number() )
rv_df %>%
group_by(line_order) %>%
mutate(boot_block1 = row_number() )
rv_df %>%
group_by(line_order) %>%
mutate(boot_block1 = ceiling(row_number() / block_size) )
# assign blocks for the bootstrap (by line)
block_size = length(timeIDs)
rv_df = rv_df %>%
arrange(!!sym(LINE_ID_NAME),!!sym(TIME_ID_NAME)) %>%
mutate(boot_block = factor( ceiling(row_number() / block_size) ) )
length(lineIDs)
# rademacher random variable for each block in the dataset
v = sample( c(-1, 1), size = length(lineIDs), replace = TRUE)
v
# rademacher random variable for each block in the dataset
v = sample( c(-1, 1), size = length(lineIDs), replace = TRUE)
v
# rademacher random variable for each block in the dataset
v = sample( c(-1, 1), size = length(lineIDs), replace = TRUE)
v
# rademacher random variable for each block in the dataset
v = sample( c(-1, 1), size = length(lineIDs), replace = TRUE)
v[rv_df$boot_block]
head(v)
v[rv_df$boot_block]
# generate wild bootstrap residuals by block
u_star = u_hat*v[rv_df$boot_block]
u_star
head(u_hat)
head(u_star)
# rademacher random variable for each block in the dataset
v = sample( c(-1, 1), size = length(lineIDs), replace = TRUE)
# generate wild bootstrap residuals by block
u_star = u_hat*v[rv_df$boot_block]
head(u_hat)
head(u_star)
head(v)
head(u_hat)
head(u_star)
knitr::opts_chunk$set(echo = TRUE)
source("readSpectra.R")
library(Matrix)
library(parallel)
library(pbmcapply)
# arguments passed to command line
# model name
MODEL_NAME = "Gauss=all_HG=all"
NUM_BOOTS = 2500
# working directory with the data
WD_DATA = "/Users/josephsalzer/research/exostat/"
# names of the timeID, lineID, and timeGroupID
TIME_ID_NAME = "date"
LINE_ID_NAME = "line_order"
# directory containing the bootstrap files
bootstrap_dir = str_c(WD_DATA, "models/", MODEL_NAME, "/wild_bootstraps" )
# create directory called "bootstrap" in model name
if ( !dir.exists(bootstrap_dir) ) {
dir.create(bootstrap_dir)
}
# read in the model fit
model_fit = readRDS(str_c(WD_DATA, "models/", MODEL_NAME, "/model.rds"))
# lm fit, df, design matrix and leverages
fit_lm = model_fit$fit_lm
rv_df = model_fit$df
designMat = model_fit$designMat
leverages = readRDS(str_c(WD_DATA, "models/", MODEL_NAME, "/leverages.rds" ))
# vec of LineIDs  in completeLines_df
lineIDs = rv_df %>% group_by(!!sym(LINE_ID_NAME)) %>% summarize(n. = n()) %>% pull(!!sym(LINE_ID_NAME))
# vec of timeIDs in completeLines_df
timeIDs = as.Date(rv_df %>% group_by(!!sym(TIME_ID_NAME)) %>% summarize(n. = n()) %>% pull(!!sym(TIME_ID_NAME)))
T_ = length(timeIDs)
L_ = length(lineIDs)
# assign blocks for the bootstrap (by line)
block_size = length(timeIDs)
rv_df = rv_df %>%
arrange(!!sym(LINE_ID_NAME),!!sym(TIME_ID_NAME)) %>%
mutate(boot_block = factor( ceiling(row_number() / block_size) ) )
wildBoot_parallel = function(seedID) {
# set a given seed for replication
set.seed(seedID)
# ensure that the rv_df is arranged first by lineID and then timeID, and that these are factors
rv_df = rv_df %>%
arrange(!!sym(LINE_ID_NAME), !!sym(TIME_ID_NAME)) %>%
mutate( lineID = factor(!!sym(LINE_ID_NAME)),
timeID = factor(!!sym(TIME_ID_NAME)))
# rademacher random variable for each block in the dataset
v = sample( c(-1, 1), size = length(lineIDs), replace = TRUE)
# generate wild bootstrap residuals by block
u_star = u_hat*v[rv_df$boot_block]
# construct bootstrap sample
y_star = fit_lm$y_hat + u_star
# re-estimate the model on bootstrap sample
fitstar_lm = sparseLM(designMat, y_star, PRINT_TIME = F)
# store data
saveRDS(fitstar_lm$beta_hat[,1],
file = str_c(bootstrap_dir, "/bootstraps_list_", seedID, ".rds" ) )
}
wildBoot_parallel(1)
# get modified residuals
u_hat = fit_lm$resid/(1-leverages)
wildBoot_parallel(1)
knitr::opts_chunk$set(echo = TRUE)
source("readSpectra.R")
library(Matrix)
library(parallel)
library(pbmcapply)
#library(lme4)
#library(car)
#library(emmeans)
#library(boot)
# autocorrelation
#library(collapse)
#library(glmm)
#library(MASS)
#library(gridExtra)
#library(glmnet)
#library(plm)
#library(sandwich)
#library(lmtest)
# working directory with the data
wd_data = "/Users/josephsalzer/research/exostat/"
# RESPONSE variable
RESPONSE = "rv_template_0.5"
# names of the timeID, lineID, and timeGroupID
TIME_ID_NAME = "date"
LINE_ID_NAME = "line_order"
TIMEGROUP_ID_NAME = "date_groups"
model_name = "Gauss=all_HG=all"
model_fit = readRDS(str_c(wd_data, "models/", model_name, "/model.rds" ))
# get the lm fit and dataframe
designMat = model_fit$designMat
responses = model_fit$responses
rv_df = model_fit$df
group_sizes = model_fit$group_sizes
modelFormula = model_fit$modelFormula
covariates = model_fit$covariates
fit_lm = model_fit$fit_lm
leverages = readRDS(str_c(wd_data, "models/", model_name, "/leverages.rds" ))
RMSE = model_fit$RMSE
# vec of LineIDs  in completeLines_df
lineIDs = rv_df %>% group_by(!!sym(LINE_ID_NAME)) %>% summarize(n. = n()) %>% pull(!!sym(LINE_ID_NAME))
# vec of timeIDs in completeLines_df
timeIDs = rv_df %>% group_by(!!sym(TIME_ID_NAME)) %>% summarize(n. = n()) %>% pull(!!sym(TIME_ID_NAME))
T_ = length(timeIDs)
L_ = length(lineIDs)
# dataframe of coefficients of current model
coef_df = tibble( coef = rownames( fit_lm$beta_hat ),
estimate = fit_lm$beta_hat[,1],
se = sqrt( diag(fit_lm$var_beta_hat) ) )
# clean RV df with +- se
cleanRV_df = model_fit$cleanRV_df %>%
mutate(lowerSE_MLE = estimate - se,
upperSE_MLE = estimate +se)
cat(model_name, "\n",
str_c("AIC: ", round(fit_lm$AIC/1e5,3), "e5" ), "\n",
str_c("BIC: ", round(fit_lm$BIC/1e5,3), "e5" ), "\n",
str_c("RSE: ", round(fit_lm$RSE,4), "\n" ),
str_c("Parameters: ", ncol(designMat), "\n"),
str_c("RMSE of cleaned RV to true planet: ", round(model_fit$RMSE,3) ), "\n",
str_c("mean se: ", round(mean( cleanRV_df$se ),3) ), "\n",
str_c("coverage 1se: ",
round(mean((cleanRV_df$estimate - cleanRV_df$se < 0) & (cleanRV_df$estimate + cleanRV_df$se > 0)),3),
"\n"),
str_c("coverage 2se: ",
round(mean((cleanRV_df$estimate - 2*cleanRV_df$se < 0) & (cleanRV_df$estimate + 2*cleanRV_df$se > 0)),3),
"\n"))
cat(model_name, "&",
ncol(designMat), "&",
str_c( "$", round(fit_lm$AIC/1e5,3), " \\times 10^5$"), "&",
str_c( "$", round(fit_lm$BIC/1e5,3), " \\times 10^5$"), "&",
round(fit_lm$RSE,3), "&",
round(model_fit$RMSE,3), "\\\\"
)
bootName = "/wild_bootstraps"
boot_files = list.files( str_c(wd_data, "models/", model_name, bootName) )
coef_list = list()
for ( i in 1:length(boot_files) ) {
coef_boot = readRDS( str_c(wd_data, "models/", model_name, bootName, "/", boot_files[i] ) )
coef_list[[i]] = coef_boot
}
# extract all vectors from boot_straps
coef_boot_df = do.call( rbind, coef_list )
rm(coef_boot, boot_files, coef_list, bootName)
# get group sizes
group_sizes = table(model_fit$timeGroup_ids[[TIMEGROUP_ID_NAME]])
# initialize 0's in the linear operator
linear_op_mat = Matrix(0, nrow = T_, ncol = length(fit_lm$beta_hat[,1]), sparse = T )
# matrix for estimating the cleaned RV
linear_op_mat[,(length(group_sizes)+1):sum(group_sizes)] = contr_groupSum(group_sizes)[,length(group_sizes):(sum(group_sizes)-1)]
# get the cleaned RV, after applying the linear operator to get the clean RV estimates for each day
# each column is the estimate for each day and each row is a boot sample
cleanRV_boot_df = coef_boot_df %*% t(linear_op_mat)
dim(coef_boot_df)
dim(linear_op_mat)
dim(cleanRV_boot_df)
# get group sizes
group_sizes = table(model_fit$timeGroup_ids[[TIMEGROUP_ID_NAME]])
# initialize 0's in the linear operator
linear_op_mat = Matrix(0, nrow = T_, ncol = length(fit_lm$beta_hat[,1]), sparse = T )
# matrix for estimating the cleaned RV
linear_op_mat[,(length(group_sizes)+1):sum(group_sizes)] = bdiag(lapply(group_sizes, function(n) contr.sum(n) ))
group_sizes
# get group sizes
group_sizes = rv_df %>%
group_by(!!sym(TIMEGROUP_ID_NAME)) %>%
summarize(size = n()/L_) %>%
pull(size)
# initialize 0's in the linear operator
linear_op_mat = Matrix(0, nrow = T_, ncol = length(fit_lm$beta_hat[,1]), sparse = T )
# matrix for estimating the cleaned RV
linear_op_mat[,(length(group_sizes)+1):sum(group_sizes)] = bdiag(lapply(group_sizes, function(n) contr.sum(n) ))
# get the cleaned RV, after applying the linear operator to get the clean RV estimates for each day
# each column is the estimate for each day and each row is a boot sample
cleanRV_boot_df = coef_boot_df %*% t(linear_op_mat)
dim(coef_boot_df)
dim(linear_op_mat)
dim(cleanRV_boot_df)
coef_boot_df[1:5,1:5]
cleanRV_boot_df[1:5,1:5]
# check for bias in original estimate vs bootstrap estimate
id = 10
ggplot() +
geom_histogram(mapping = aes(x = cleanRV_boot_df[,id]), bins = 40) +
geom_vline(xintercept = cleanRV_df$estimate[id] )
rm(id)
coef_boot_df
head(coef_boot_df)
dim(coef_boot_df)
dim(coef_boot_df[1:5,1:5])
coef_boot_df[1:5,1:5]
coef_boot_df[,1:5]
coef_boot_df[1,1:5]
coef_boot_df[1:5,1:5]
# get the cleaned RV, after applying the linear operator to get the clean RV estimates for each day
# each column is the estimate for each day and each row is a boot sample
cleanRV_boot_df = coef_boot_df %*% t(linear_op_mat)
coef_boot_df[1:5,1:5]
cleanRV_boot_df[1:5,1:5]
