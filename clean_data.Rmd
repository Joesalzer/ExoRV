---
title: "NEID Solar Data -- Clean Data"
author: "Joe Salzer"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("readSpectra.R")
```

```{r}
## data directory
wd_data = "/Users/josephsalzer/research/exostat/line_property_files/"
```

# read data

## join all files

```{r}
# list of files in line_property_files
files = list.files("line_property_files", pattern = ".h5")
# sample random 5 from files
#files = list.files("line_property_files", pattern = ".h5")[1:5]
```

```{r}
# file with the projection onto gh coefs that are orthogonal to a Doppler shift
template_deriv_onto_gh = H5Fopen("project_template_deriv_onto_gh.h5")
```

```{r}
# create an empty list to store datasets
dataset_list = list()
# start time
START_TIME = Sys.time()

for (i in 1:length(files) ) {
  
  # read file,  loadLineShape returns a list containing the line shape info as well as the template line and hg-reconstructed 
  # if it failed to load the file then it returns a string called "failed"
  loaded_lineshape = loadLineShape(files[i])
  
  # go to next if it failed to load
  if ( any( is.na( loaded_lineshape$line.df ) )  ) {
    print("NA present, skip to next index")
    print(i)
    next
  }
  
  # temporary line property df
  temp_df = loaded_lineshape$line.df
  
  # index of template_deriv_onto_gh that matches this file name
  template_deriv_onto_gh_ID = which(str_sub(files[i], end = -8) == str_sub(template_deriv_onto_gh$filename, end = -4))
  
  # if theres a unique match
  if ( length(template_deriv_onto_gh_ID) == 1 ) {
    
    # column names for the hg coefficients
    hg_colnames = temp_df %>% select(starts_with("hg") ) %>% colnames()
    # column names for the hg coefficients
    thg_colnames = temp_df %>% select(starts_with("thg") ) %>% colnames()
    
    # vector showing how a Doppler shift projects onto GH coefficients for a single line
    d_gh = template_deriv_onto_gh$gh_vs_mps_coeffs[1:11,2,template_deriv_onto_gh_ID]
    d_tgh = template_deriv_onto_gh$tgh_vs_mps_coeffs[1:11,2,template_deriv_onto_gh_ID]
    
    # matrix of original hg/thg coefficients for a single line over each time
    # T x 11 matrix
    HG = ( temp_df %>% select(starts_with("hg")) %>% as.matrix() )
    THG = ( temp_df %>% select(starts_with("thg")) %>% as.matrix() )
    
    # find orthogonal, "cleaned" gh coefficients
    # each element in the rows of the matrix rep(1,345) %*% t(d) are multiplied by the corresponding element of the vector G %*% d /sum(d*d)
    # HG_perp = HG - sweep( x = rep(1,345) %*% t(d_gh), MARGIN = 1, STATS = HG %*% d_gh / sum(d_gh*d_gh), FUN = "*")
    # THG_perp = THG - sweep( x = rep(1,345) %*% t(d_tgh), MARGIN = 1, STATS = THG %*% d_tgh / sum(d_tgh*d_tgh), FUN = "*")
    HG_perp = HG - (HG %*% d_gh) %*% t(d_gh) / sum(d_gh * d_gh)
    THG_perp = THG - (THG %*% d_tgh) %*% t(d_tgh) / sum(d_tgh * d_tgh)
    
    # store the perpendicular hg coefficients into the temp dataframe
    temp_df[ str_c("proj_", hg_colnames) ] = HG_perp
    temp_df[ str_c("proj_", thg_colnames) ] = THG_perp
    
  } else {
    print("Failed to produce orthogonal gh")
    print(i)
  }
  
  # store loaded_lineshape$line.df into dataset list
  dataset_list[[i]] = temp_df
}

# combine all df into a single df
final_df = do.call(rbind, dataset_list)
# remove files
rm(dataset_list)
# end time
end.time = Sys.time()
# print
print(end.time - START_TIME)
```

## removing lines based on orders

76 lines removed

*REMOVING SOME PROBLEMATIC ORDERS:*

```{r}
final_df %>%
  filter( (order_idx %in% c(56,57,58)) ) %>%
  count(line_order) %>%
  nrow()
```

```{r}
final_df %>%
  filter( (order_idx %in% c(56,57,58)) ) %>%
  select(order_phys) %>%
  count(order_phys)
```

```{r}
final_df = final_df %>%
  filter( !(order_idx %in% c(56,57,58)) )
```

## removing lines based on shape parameter b at -.7, .7

49 lines removed

```{r}
limit_b_lines = final_df %>%
  filter( abs(fit_gauss_b) == .7 ) %>%
  count(line_order) %>%
  pull(line_order)

limit_b_lines
length(limit_b_lines)
```

```{r}
final_df = final_df %>%
  filter( !(line_order %in% limit_b_lines) )
```

```{r}
rm(limit_b_lines)
```

## removing lines based on sd of covariates

5 lines removed

```{r}
# covariates
covars = c("fit_gauss_a", "fit_gauss_b", "fit_gauss_depth", "fit_gauss_sigmasq", str_c("hg_coeff_", seq(0,10)), str_c("thg_coeff_", seq(0,10)))
```

```{r}
sd_df = final_df %>%
  group_by(line_order) %>%
  summarize_at(covars, sd) %>%
  filter_at(covars, any_vars(. == 0) )
head(sd_df)
nrow(sd_df)
```
Some lines have constant (sd of exactly 0) values for b and sigmasq

```{r}
final_df = final_df %>%
  filter(!(line_order %in% sd_df$line_order))
```

```{r}
rm(covars, sd_df)
```

## removing lines where gaussian fit didnt coverge

2 lines removed
```{r}
notConverged = final_df %>%
  filter(fit_gauss_converged == 0) %>%
  count(line_order) %>%
  pull(line_order)
notConverged
```

```{r}
final_df = final_df %>%
  filter( !(line_order %in% notConverged) )

rm(notConverged)
```

## remove days that were poorly calibrated (after fire, before dec 1)

15 days removed

```{r}
badcalibrate_days = final_df %>%
  dplyr::select(date,date_groups) %>%
  unique() %>%
  filter(date_groups == 2,
         date <= "2022-12-01") %>%
  pull(date)

final_df = final_df %>%
  filter(!(date %in% badcalibrate_days ))

print(badcalibrate_days)
length(badcalibrate_days)
rm(badcalibrate_days)
```

## write file
```{r}
# write to csv
write_csv(final_df, "/Users/josephsalzer/research/exostat/completeLines.csv")
```

# summaries

```{r}
# read data
final_df = read_csv("/Users/josephsalzer/research/exostat/completeLines.csv")
```


```{r}
summary(final_df)
```

```{r}
summary(final_df)
```

778 line-orders
330 days

```{r}
all( ( final_df %>% count(date) )$n == 778 )

all( ( final_df %>% count(line_order) )$n == 330 )
```


