---
title: "NEID Solar Data -- loading raw spectra"
author: "Joe Salzer"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("readSpectra.R")
library(MASS)
```

```{r}
## Data directory
wd_data = "/Users/josephsalzer/research/exostat/line_property_files/"
```

# seperate models combined into one

```{r}
set.seed(123)
# example df with 10 lines
temp_df = final_df %>%
  filter(line_order %in% sample(lines,10)) %>%
  #filter(date%in% sample(days,20)) %>%
  rename(rv = rv_template_0.5, depth = fit_gauss_depth, width = fit_gauss_sigmasq) %>%
  dplyr::select(line_order,date,date_groups,rv,depth,width) %>%
  arrange(line_order,date)

# group 1 data
group1_df = temp_df %>%
  filter(date_groups == 1) %>%
  mutate(date = factor(date),
         line_order = factor(line_order))
# group 2 data
group2_df = temp_df %>%
  filter(date_groups == 2) %>%
  mutate(date = factor(date),
         line_order = factor(line_order))
# combined group 1 and 2
temp_df = temp_df %>%
  mutate(date = factor(date),
         line_order = factor(line_order),
         lineOrderIntercept_groups = factor(str_c(line_order,"_group",date_groups)),
         lineOrderSlope_groups = factor(str_c(line_order,"_group",date_groups)))
```

```{r}
group_sizes = c(5,5)
num_lines = 3

# group 1 linear model
group1_lm = lm(rv ~ date + line_order + depth + width + line_order:depth + line_order:width, group1_df, contrasts = list(date = "contr.sum", line_order = "contr.sum"))
# group 2 linear model
group2_lm = lm(rv ~ date + line_order + depth + width + line_order:depth + line_order:width, group2_df, contrasts = list(date = "contr.sum", line_order = "contr.sum"))

# grouped linear model
grouped_lm = lm(rv ~ date + lineOrderIntercept_groups + depth + width + lineOrderSlope_groups:depth + lineOrderSlope_groups:width, temp_df,
                contrasts = list(date = timeFE_contrast(group_sizes),
                                 lineOrderIntercept_groups = lineGroupFE_contrast(group_sizes,num_lines),
                                 lineOrderSlope_groups = contr.sum))

print("group 1")
predict(group1_lm)
print("group 2")
predict(group2_lm)
print("combined")
predict(grouped_lm)
```

```{r}
summary(group1_lm)
summary(group2_lm)
summary(grouped_lm)
```


```{r}
library(lme4)
```

```{r}
temp_df
```




# testing contr_groupSum

```{r}
# grand means
mu_1 = 9
mu_2 = -4
mu_3 = 0
# offsets from grand means
# from 1st grand mean
alpha_1 = 6
alpha_2 = -2
alpha_3 = -(alpha_1+alpha_2)
# from 2nd grand mean
alpha_4 = .3
alpha_5 = -alpha_4
# from 3rd grand mean
alpha_6 = 4
alpha_7 = -1
alpha_8 = -(alpha_6+alpha_7)
sigma = .2

mus = c(mu_1,mu_2,mu_3)
alphas = c(alpha_1,alpha_2,alpha_3,alpha_4,alpha_5,alpha_6,alpha_7,alpha_8)
n_group = 5
```


```{r}
set.seed(123)
# create a sample data frame
df = data.frame(
  group = factor( rep( 1:8, each = n_group ) ),
  alpha = rep(alphas, each = n_group),
  mu = c( rep(mu_1, 3*n_group), rep(mu_2,2*n_group), rep(mu_3,3*n_group) )
)
df$eps = rnorm(n = nrow(df), mean = 0, sd = sigma)
df$response = df$mu + df$alpha + df$eps
df
```

G = number of groups
\mathbf{g} = vector of groups = g1, g2, ..., gG

```{r}
contr_groupSum(c(4,3,5))
dim(contr_groupSum(c(4,3,5)))
```


first columns of the contrast matrix
```{r}

```

```{r}
group_sizes = c(4,5)
# number of groups
num_groups = length(group_sizes)
contr.sum(num_groups)
bdiag( lapply(group_sizes, FUN = function(x) rep(1,x) ) ) %*% contr.sum(num_groups)
contr.sum(num_groups)[rep(1:num_groups,times = group_sizes), ]
```



```{r}
bdiag(lapply(group_sizes, contr.sum))
block_diagonal(lapply(group_sizes, contr.sum))
```

```{r}
designMat = model.matrix(~group, df, contrasts.arg = list(group = group_sum_contrast(group_sizes)))
response = df$response
```

```{r}
betas = sparseLM(designMat,response)$beta_hat
dim(betas)
betas
```

```{r}
# initialize 0's in the linear operator
linear_op_mat = matrix(data = 0, nrow = sum(group_sizes), ncol = length(betas[,1]) )
# matrix of for estimating the cleaned RV
linear_op_mat[,(length(group_sizes)+1):sum(group_sizes)] = group_sum_contrast(group_sizes)[,length(group_sizes):(sum(group_sizes)-1)]
dim(linear_op_mat)
```

```{r}
linear_op_mat %*% betas
print(alphas)
```


# modeling a sin-wave planet

```{r}
set.seed(1)
# sin (planet) wave
amp = 3
orbit = 40
freq = 2*pi/orbit
horizontal_offset = 30
vertical_offset = 1.5

# number of time points
n_time = 100
# number of lines
n_line = 6

# get the days to have obs from, 4 orbits
days = sort( sample( seq(0,orbit*3), n_time, replace = F ) )
# true rv signal
trueRV = vertical_offset + amp*sin(freq*days + horizontal_offset)
# time FE, alpha parameters are the planetary rv wrt abitrary mean
alphas = trueRV - mean(trueRV)
```

```{r}
ggplot() +
  geom_point(mapping = aes(x = days, y = trueRV))
```

```{r}
set.seed(123)
# (random) slope of the depth for each line
thetas = rnorm(n_line, sd = 2)
# (random) intercept for each line
line_intercepts = rnorm(n_line, sd = 1.5) 
betas = line_intercepts - mean(line_intercepts)
```

```{r}
# create a sample data frame
df = data.frame(
  date = rep( days, each = n_line ),
  trueRV = rep( trueRV, each = n_line ), 
  lineID = factor( rep( str_c("line",1:n_line), n_time) ),
  theta = rep(thetas, n_time),
  line_intercept = rep(line_intercepts, n_time),
  beta = rep(betas, n_time)
)

df = df %>%
  arrange(lineID, date) %>%
  group_by(lineID) %>%
  mutate(depth = rnorm(n_time),
         depth_centered = depth - mean(depth)) %>%
  ungroup() %>%
  mutate(line_offset = line_intercept + theta*depth_centered,
         timeID = factor(date))

contrasts(df$lineID) = contr.sum
contrasts(df$timeID) = contr.sum
```

```{r}
df %>% ggplot() +
  geom_line(mapping = aes(x = date, y = trueRV)) +
  geom_point(mapping = aes(x = date, y = trueRV+line_offset), color = "red", size = .5)
```




## customizing noise


```{r}
constantNoise = function(rvDF, sigma) {
  return( rnorm(nrow(rvDF),mean=0,sd=sigma) )
}
```

```{r}
heteroNoiseNoAuto = function(rvDF,sigmas,T_) {
  return( mvrnorm(n = 1, mu = 0, Sigma = diag(rep(sigmas,each=T_)) ) )
}
```

```{r}
set.seed(123)
sigmas = runif(n_line,min=0,max=4)
sigmas
T_ = 100
diag(rep(sigmas,each=T_))[1:5,1:5]
diag(rep(sigmas,each=T_))[100:105,100:105]
```

```{r}
diag(c(2,2,1,1))
```



```{r}
## no autocorrelation, no heteroskedasticity
df$contamRV = mvrnorm(n = 1, mu = df$trueRV + df$line_offset, Sigma = df$sigma^2*diag(nrow(df)) )

## no autocorrelation
#df$contamRV = mvrnorm(n = 1, mu = trueRV + lineEffect, Sigma = .8^2*diag(n_time) )

## with autocorrelation
#df$contamRV = mvrnorm(n = 1, mu = trueRV + lineEffect, Sigma = covar_mat )
```

```{r}
rep()
```

```{r}
sigmas*diag(nrow(df))[1:5,1:5]
sigmas*diag(nrow(df))[100:105,100:105]
```

```{r}
mvrnorm(n = 1, mu = rep(0,nrow(df)), Sigma = sigmas*diag(nrow(df)) )
```

```{r}
set.seed(1)
sigmas = runif(n_line,min=0,max=3)
sigmas
```
```{r}
rnorm(1, sd = sigmas )
```

```{r}
#rep( sigmas, each = n_time)
```

```{r}
df %>%
  group_by(lineID) %>%
  mutate(sigma_ = sigmas) %>%
  ungroup()
```

```{r}
df
```

```{r}
#
```


```{r}
sigma = 1
```

```{r}
num_montecarlo = 200
bias_df = matrix(NA, nrow = num_montecarlo, ncol = n_time)

for (i in 1:num_montecarlo) {
  noise = rnorm(nrow(df),mean=0,sd=sigma)
  df$contamRV = df$trueRV + df$line_offset + noise
  lm_fit = lm(contamRV ~ timeID + lineID + lineID:depth_centered, df)
  coef_df = summary(lm_fit)$coefficients
  alpha_hat = coef_df[startsWith(rownames(coef_df),"timeID"),1]
  alpha_hat = c(alpha_hat,-sum(alpha_hat))
  
  bias_df[i,] = (alphas - alpha_hat)
}
```

```{r}
summary(bias_df[,1])
```

## testing manual random effects modeling

```{r}
library(lme4)
```

```{r}
sigma = 1
noise = rnorm(nrow(df),mean=0,sd=sigma)
df$contamRV = df$trueRV + df$line_offset + noise
```

```{r}
fe_lm = lm(contamRV ~ timeID + lineID + lineID:depth_centered, df)
```

rmse with fe
```{r}
alphas_hat = fe_lm$coefficients[startsWith(names(fe_lm$coefficients),"timeID")]
alphas_hat = c(alphas_hat,-sum(alphas_hat))

sqrt( mean( (alphas_hat - alphas)^2 ) )
```

```{r}
me_lm = lmer(contamRV ~ timeID + (1+depth_centered|lineID), df)
```

```{r}
alphas_hat_me = fixef(me_lm)[startsWith(names(fixef(me_lm)),"timeID")]
alphas_hat_me = c(alphas_hat_me,-sum(alphas_hat_me))

sqrt( mean( (alphas_hat_me - alphas)^2 ) )
```























## creating a covariance matrix
```{r}
# kernel_func = function(x, y, var, lengthscale){
#   return( var*exp( -(x-y)^2/(2*lengthscale^2) ) )
# }
# # create covariance matrix
# covar_mat = outer( days, days, FUN = kernel_func, var = .8^2, lengthscale = 3)
# covar_mat[1:5,1:5]
# dim(covar_mat)
# kernel_func(0,18,.8^2,10)
```

```{r}
# noise terms for each line
sigmas = c(1.8, .3, 1.5, .05, .1, .8)
df$sigma = rep( sigmas, each = n_time)
```


```{r}
# sample contaminaated RV from a mvn model

## no autocorrelation, no heteroskedasticity
df$contamRV = mvrnorm(n = 1, mu = df$trueRV + df$line_offset, Sigma = df$sigma^2*diag(nrow(df)) )

## no autocorrelation
#df$contamRV = mvrnorm(n = 1, mu = trueRV + lineEffect, Sigma = .8^2*diag(n_time) )

## with autocorrelation
#df$contamRV = mvrnorm(n = 1, mu = trueRV + lineEffect, Sigma = covar_mat )
```

EDA

```{r}
# no autocorrelation
df %>% ggplot() +
  geom_line(mapping = aes(x = date, y = trueRV)) +
  geom_point(mapping = aes(x = date, y = contamRV), color = "red", size = .5) +
  ylim(-8,8)
```

```{r}
## Train/test split
set.seed(123)

test_days = sample( unique(df$date), 5)
# remove some days as a testing set
df_test = df %>%
  filter(date %in% test_days )

df_train = df %>%
  filter( !(date %in% test_days ) )
```

Build linear model
```{r}
# set factors
df_train = df_train %>%
  mutate(timeID = factor(date))

df_test = df_test %>%
  mutate(timeID = factor(date))

df_train
df_test
```

unweighted
```{r}

lm_fit_sum2zero = lm(contamRV ~ timeID + lineID , df_train)
sum_lm_sum2zero = summary(lm_fit_sum2zero)
cleanedRV = sum_lm_sum2zero$coefficients[1,1] + 
  c( sum_lm_sum2zero$coefficients[startsWith(rownames(sum_lm_sum2zero$coefficients),"timeID"),1],
   -sum(sum_lm_sum2zero$coefficients[startsWith(rownames(sum_lm_sum2zero$coefficients),"timeID"),1]) )
```

```{r}
head(cleanedRV)
```

weighted
```{r}
# deisign matrix
contrasts( df_train$timeID ) = contr.sum
contrasts( df_train$lineID ) = contr.sum
X = model.matrix(~ timeID + lineID , df_train)
# weight matrix
W = diag( rep( w, each = length(unique(df_train$date))) )
Y = df_train$contamRV

model_coefs = solve(t(X) %*% W %*% X) %*% t(X) %*% W %*%Y
```

```{r}
alphas = model_coefs[startsWith(rownames(model_coefs),"timeID"),1]
alphas = c(alphas, -sum(alphas))
betas = model_coefs[startsWith(rownames(model_coefs),"lineID"),1]
betas = c(betas, -sum(betas))
mu = unname( model_coefs[1,1] )
```

```{r}
mu + alphas[2] + mean(w*betas)
```

```{r}
contrasts( df_train$timeID ) = contr.sum
contrasts( df_train$lineID ) = contr.sum

lm_fit_sum2zero = lm(contamRV ~ timeID + lineID , df_train,
                     weights = rep( w, each = length(unique(df_train$date))) )
sum_lm_sum2zero = summary(lm_fit_sum2zero)

em = emmeans(lm_fit_sum2zero, ~ timeID, weights = "proportional")
head(em)

df_train$predRV = lm_fit_sum2zero$fitted.values

df_train %>%
  mutate(weight_predRV = rep( w, each = length(unique(df_train$date)))*predRV) %>%
  group_by(date) %>%
  summarize(em = mean(weight_predRV)) %>%
  head()

df_train %>%
  group_by(date) %>%
  summarize(em = mean(w*contamRV)) %>%
  head()
```















```{r}
df_train %>%
  group_by(date) %>%
  summarize(trueRV = mean(trueRV),
            contamRV = mean(contamRV)) %>%
  mutate(cleanedRV = cleanedRV) %>%
  ggplot() +
  geom_line(mapping = aes(x = date, y = trueRV)) +
  geom_point(mapping = aes(x = date, y = contamRV), color = "blue", size = .5) +
  geom_point(mapping = aes(x = date, y = cleanedRV), color = "orange", size = .5)
  
  
  
df_train %>%
  group_by(timeID) %>%
  summarize(trueRV = mean(trueRV),
            contamRV = mean(contamRV)) %>%
  mutate(cleanedRV = cleanedRV) %>%
  summarize( rmse_contam = sqrt( mean((trueRV - contamRV)^2) ),
             rmse_clean = sqrt( mean((trueRV - cleanedRV)^2) ))
```

```{r}
# in sample predictions
pred_sum2zero = predict.lm(lm_fit_sum2zero, df_train)
```

```{r}
# do prediction on test data

# get model parameters not associated with date
betas_noDate_sum2zero = sum_lm_sum2zero$coefficients[!startsWith(rownames(sum_lm_sum2zero$coefficients),"timeID"),1]
contrasts( df_test$timeID ) = contr.sum
contrasts( df_test$lineID ) = contr.sum
# get design matrix for test data without date
X_sum2zero = model.matrix(contamRV ~ lineID + depth_centered + lineID:depth_centered, df_test)

testpred_sum2zero = X_sum2zero %*% betas_noDate_sum2zero
```




```{r}
df_test %>%
  mutate(cleanRV_treatment = contamRV-testpred_treatment,
         cleanRV_sum2zero = contamRV-testpred_sum2zero) %>%
  summarize(rmse_treatment = sqrt(mean((trueRV-cleanRV_treatment)^2) ),
            rmse_sum2zero = sqrt(mean((trueRV-cleanRV_sum2zero)^2)) )
```


# CV

ONE PARTICULAR LINE HAD A SD OF 0 FOR fit_gauss_b ONCE WE REMOVED A DAY
thus, the XtX matrix is singular for this CV-day

```{r}
cv1 = cv_parallel(242)
```


```{r}
cv_day = cv_days[242]
# test index if we leave out a given day
cv_index = ( final_df$date == final_days[cv_day] )

# get standardized rv dataframe, train and test datasets
standardized_list = standardize(final_df, covars = covars, covars_pca = covars_pca, test_index = cv_index)
train_df = standardized_list$train.df %>%
  mutate(date = factor(date),
         line_order = factor(line_order))
test_df = standardized_list$test.df%>%
  mutate(date = factor(date),
         line_order = factor(line_order))

# (sparse) design matrix for model
X_train = sparse.model.matrix(model_formula, train_df)
# responses
Y_train = train_df$rv_template_0.5
# fit the linear model on the train data
fit_train_lm = sparseLM(X_train, Y_train, PRINT_TIME = F)
```

```{r}
XtX_inv = solve( t(cv1) %*% cv1, tol = 1e-23 )
```

```{r}
test_df
```

```{r}
train_df %>%
  group_by(line_order) %>%
  summarize_at(covars, sd) %>%
  filter_at(covars, any_vars(. == 0) )
```

```{r}
# (sparse) design matrix for model, without date
X_test = sparse.model.matrix(update(model_formula, ~ . - date), test_df)
# responses
Y_test = test_df$rv_template_0.5

# get rid of model coefficients associated with date
model_coefs_nodate = fit_train_lm$beta_hat[ !startsWith( rownames(fit_train_lm$beta_hat), "date"), ]

# make sure our design matrix and coefficients are the same
if (!all( names(model_coefs_nodate) == colnames( X_test ) )) {
  print("error in conforming matrices")
  next
}

# create a column for predicted rvs
test_df[["pred_rv"]] = (X_test %*% model_coefs_nodate)[,1]
```

```{r}
# cv_list <- lapply(cv_days, FUN = cv_parallel)
# cv_df = do.call(rbind, cv_list)
# rm(cv_list)
# 
# saveRDS(cv_df, file = str_c(wd_data, "models/", model_name, "/cv_cleaned.rds" ) )
```

```{r}
# # create an empty list to store datasets
# cv_list = list()
# # start time
# START_TIME = Sys.time()
# 
# for (i in 1:length(cv_days) ) {
#   cv_day = cv_days[i]
#   # test index if we leave out a given day
#   cv_index = ( final_df$date == final_days[cv_day] )
# 
#   # get standardized rv dataframe, train and test datasets
#   standardized_list = standardize(final_df, covars = covars, covars_pca = covars_pca, test_index = cv_index)
#   train_df = standardized_list$train.df %>%
#     mutate(date = factor(date),
#            line_order = factor(line_order))
#   test_df = standardized_list$test.df%>%
#     mutate(date = factor(date),
#            line_order = factor(line_order))
# 
#   # (sparse) design matrix for model
#   X_train = sparse.model.matrix(model_formula, train_df)
#   # responses
#   Y_train = train_df$rv_template_0.5
#   # fit the linear model on the train data
#   fit_train_lm = sparseLM(X_train, Y_train, PRINT_TIME = F)
# 
#   # (sparse) design matrix for model, without date
#   X_test = sparse.model.matrix(update(model_formula, ~ . - date), test_df)
#   # responses
#   Y_test = test_df$rv_template_0.5
# 
#   # get rid of model coefficients associated with date
#   model_coefs_nodate = fit_train_lm$beta_hat[ !startsWith( rownames(fit_train_lm$beta_hat), "date"), ]
# 
#   # make sure our design matrix and coefficients are the same
#   if (!all( names(model_coefs_nodate) == colnames( X_test ) )) {
#     print("error in conforming matrices")
#     next
#   }
# 
#   # create a column for predicted rvs
#   test_df[["pred_rv"]] = (X_test %*% model_coefs_nodate)[,1]
#   # store dataset
#   cv_list[[i]] = test_df %>%
#     rename(contam_rv = rv_template_0.5) %>%
#     select(date, line_order, contam_rv, pred_rv)
# 
#   # cleanup
#   rm(cv_day, cv_index, standardized_list, train_df, test_df, X_train, Y_train, fit_train_lm, X_test, Y_test, model_coefs_nodate)
# 
#   # print
#   print(str_c("day ", i))
# }
# 
# # combine all df into a single df
# cv_df = do.call(rbind, cv_list)
# 
# rm(cv_list)
```


